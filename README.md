ğŸµ Speech & Music Dereverberation System

State-of-the-art deep learning system for removing reverberation from speech and music signals, optimized for competition performance.

ğŸ“Œ Author: kris07hna
ğŸ“Œ Competition: Audio Dereverberation Challenge 2025
ğŸ“Œ Last Updated: 2025-08-25 23:35:29 UTC

ğŸ“‹ Table of Contents

ğŸ¯ Overview

ğŸ† Key Features

ğŸ—ï¸ Architecture

ğŸ“Š Performance

ğŸš€ Quick Start

ğŸ“ Dataset Structure

âš™ï¸ Configuration

ğŸ”§ Training

ğŸ“ˆ Evaluation

ğŸ“Š Competition Metrics

ğŸ¯ Model Complexity

ğŸ“‚ File Structure

ğŸ”— Dependencies

ğŸ› Troubleshooting

ğŸ“„ License

ğŸ¤ Contributing

ğŸ¯ Overview

This repository contains a professional-grade dereverberation system that transforms reverberant (echo-filled) audio signals into clean, high-quality audio using advanced deep learning techniques.

Why Dereverberation?

âœ”ï¸ Speech Clarity â€“ better intelligibility for calls, meetings, and AI assistants
âœ”ï¸ Music Quality â€“ clean audio for mixing, mastering, and production
âœ”ï¸ Audio Processing â€“ enhanced input for downstream ML/AI tasks

Competition Context

Task: Remove reverberation from speech and music

Metrics: PESQ (speech quality) + SDR (music quality)

Constraint: Model complexity < 50 GMAC/s

Dataset: Paired reverberant â†” clean audio samples

ğŸ† Key Features

ğŸ”¥ Advanced Architecture

DPRNN-UNet hybrid with bidirectional LSTM bottleneck

Multi-scale skip connections

Mixed precision (FP16/FP32) training

ğŸ“Š Full Dataset Support

Handles 1000+ WAV files

Smart reverberant â†” clean pairing

Memory-efficient lazy loading

ğŸ¯ Competition-Focused Optimization

Tuned for PESQ (speech) + SDR (music)

Verified complexity: 35â€“45 GMAC/s (<50)

Professional metrics: PESQ, SDR, STOI

âš¡ Training Efficiency

Multi-domain loss (time + frequency)

Gradient clipping + early stopping

Fast convergence: 25â€“35 epochs

ğŸ—ï¸ Architecture
INPUT (Reverberant Audio)
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ENCODER PATH         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1D Conv: 1â†’32 channels  â”‚ â† Fine features
â”‚ 1D Conv: 32â†’64 channels â”‚ â† Mid features  
â”‚ 1D Conv: 64â†’128 channelsâ”‚ â† High features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LSTM BOTTLENECK       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ BiLSTM temporal model â”‚
â”‚ â€¢ 128â†’64â†’128 channels   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    DECODER PATH         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 128â†’64 + skip fusion    â”‚
â”‚ 64â†’32  + skip fusion    â”‚
â”‚ 32â†’1   + skip fusion    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
OUTPUT (Clean Audio)

ğŸ“Š Performance

ğŸ† Expected Results (on 1000+ training pairs):

ğŸ¤ PESQ (Speech): 3.0 â€“ 3.4 âœ… (Excellent)

ğŸµ SDR (Music): 12 â€“ 18 dB âœ… (Very Good)

ğŸ—£ï¸ STOI (Intelligibility): 0.7 â€“ 0.85 âœ… (Good)

âš¡ Complexity: ~42 GMAC/s âœ… (<50)

ğŸš€ Quick Start
1ï¸âƒ£ Installation
git clone https://github.com/kris07hna/dereverberation.git
cd dereverberation

pip install -r requirements.txt

2ï¸âƒ£ Prepare Dataset
dataset/
â”œâ”€â”€ reverb/
â”‚   â”œâ”€â”€ reverb_001.wav
â”‚   â”œâ”€â”€ reverb_002.wav
â””â”€â”€ clean/
    â”œâ”€â”€ clean_001.wav
    â”œâ”€â”€ clean_002.wav

3ï¸âƒ£ Train Model
python train_dereverberation.py \
    --reverb_dir "/path/to/reverb" \
    --clean_dir "/path/to/clean" \
    --epochs 35 \
    --batch_size 8

4ï¸âƒ£ Evaluate Model
python evaluate_model.py \
    --model_path "best_model.pth" \
    --test_dir "/path/to/test"

ğŸ“ˆ Evaluation

Example output after training:

ğŸ† COMPREHENSIVE RESULTS
ğŸ‘¤ User: kris07hna
ğŸ“Š Training samples: 1247
ğŸ”¬ Evaluation samples: 300

âš¡ MODEL:
   Complexity: 42.3 GMAC/s âœ…
   Status: PASS

ğŸ¯ METRICS:
   ğŸ¤ PESQ: 3.124 Â± 0.234 (Very Good)
   ğŸµ SDR:  14.7 Â± 3.2 dB (Very Good)
   ğŸ—£ï¸ STOI: 0.782 Â± 0.089 (Good)

ğŸ† COMPETITION SCORE: 3.456

ğŸ¯ Model Complexity

ğŸ”¢ Complexity measured with ptflops:

from models.complexity import GMACalculator
gmacs = GMACalculator.calculate_gmacs(model, (1,16000))
print(f"Complexity: {gmacs:.2f} GMAC/s")


âœ… Constraint: <50 GMAC/s

ğŸ“‚ File Structure
dereverberation/
â”œâ”€â”€ train_dereverberation.py     # Training script
â”œâ”€â”€ evaluate_model.py            # Evaluation script
â”œâ”€â”€ models/                      # Architectures + GMAC calc
â”œâ”€â”€ data/                        # Dataset + preprocessing
â”œâ”€â”€ metrics/                     # PESQ, SDR, STOI
â”œâ”€â”€ utils/                       # Training utils, viz
â”œâ”€â”€ configs/                     # Default + competition configs
â”œâ”€â”€ outputs/                     # Models, logs, results
â””â”€â”€ requirements.txt             # Dependencies

ğŸ”— Dependencies
torch>=2.0.0
torchaudio>=2.0.0
numpy>=1.21.0
scipy>=1.7.0
pesq>=0.0.4
pystoi>=0.3.3
ptflops>=0.6.9
tqdm>=4.64.0
matplotlib>=3.5.0
pandas>=1.3.0

ğŸ“„ License

MIT License Â© 2025 kris07hna

ğŸ¤ Contributing

We welcome contributions! ğŸš€

Fork repo

Create feature branch (git checkout -b feature/improvement)

Commit changes (git commit -m 'Add improvement')

Push to branch (git push origin feature/improvement)

Open Pull Request

ğŸ”¥ Ready for competition submission!
âœ”ï¸ <50 GMAC/s
âœ”ï¸ High PESQ + SDR
âœ”ï¸ Full dataset support
âœ”ï¸ Leaderboard-ready
